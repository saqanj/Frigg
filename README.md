- FRIGG: Moderation Model for Distinguishing "Art" from "CP" (Child Pornography) on Generative Art Platforms
- ABOUT: Inspired by OpenAI's Moderation API, DreamUp.AI wanted to try and replicate it in their own platform. The reason being is that it would allow for the creation of more detailed art by creating more specific moderation categories like "CP", "Gore", etc. as opposed to filtering anything remotely explicit which is what their current moderation model did. Although this model did not achieve that, it layed the ground work for future categories. So then, search queries involving even slightly explicit vocabulary would not be flagged, while omitting illegal requests. This is currently not being used due to it not having been fully complete, but is still incredibly powerful at categorizing between the two. Completed in a 2 man team including myself and served as a disgusting but impactful introduction to the complexities of Deep Learning & Natural Language Processing in my first college summer.
- HOW TO ACCESS: Please reach out to me if you would like access to the dataset, model, and training source code. I unfortunately cannot post the model due to its size being too large to hold on Github, and the dataset and source code are incredibly explicit. All that the github contains is related training and evaluation documentation.
  - EMAIL: saqlainanjum13@gmail.com
